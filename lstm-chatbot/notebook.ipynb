{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchtext 0.9.0\n",
      "Uninstalling torchtext-0.9.0:\n",
      "  Successfully uninstalled torchtext-0.9.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==1.8.0 in /root/.local/lib/python3.7/site-packages (1.8.0)\n",
      "Collecting torchtext==0.9.0\n",
      "  Using cached torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "Requirement already satisfied: torch-utils in /root/.local/lib/python3.7/site-packages (0.1.2)\n",
      "Requirement already satisfied: datasets in /root/.local/lib/python3.7/site-packages (2.13.1)\n",
      "Requirement already satisfied: transformers in /root/.local/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (3.7.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (4.43.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: aiohttp in /root/.local/lib/python3.7/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (20.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /root/.local/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /root/.local/lib/python3.7/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: xxhash in /root/.local/lib/python3.7/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /root/.local/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: filelock in /root/.local/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/.local/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.3.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/.local/lib/python3.7/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/.local/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (2.4.6)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.9.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.0-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.13.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Downloading widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 45.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets~=3.0.7\n",
      "  Downloading jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 61.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting comm>=0.1.3\n",
      "  Downloading comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (45.2.0.post20200209)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets) (0.6.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.1.8)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, comm, ipywidgets\n",
      "Successfully installed comm-0.1.4 ipywidgets-8.1.0 jupyterlab-widgets-3.0.8 widgetsnbextension-4.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torchtext==0.12.0 -y\n",
    "!pip install torch==1.8.0 torchtext==0.9.0 torch-utils datasets transformers\n",
    "!pip install ipywidgets\n",
    "\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"My main Seq2Seq model, with encoder and decoder layers.\"\"\"\n",
    "\n",
    "import random\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"My Encoder layer.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, embedding_dim: int) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)  # , hidden_size?\n",
    "        self.lstm_1 = nn.LSTM(  # type: ignore\n",
    "            embedding_dim, self.hidden_size * 2, 4, dropout=0.5, batch_first=True\n",
    "        )\n",
    "        self.lstm_2 = nn.LSTM(  # type: ignore\n",
    "            self.hidden_size * 2, self.hidden_size * 4, 4, dropout=0.2\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Any, Any]:\n",
    "        \"\"\"\n",
    "        Forward method for the tensor network.\n",
    "\n",
    "        Todo\n",
    "        ----\n",
    "        * Define the Any's at the return type\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            x : Tensor\n",
    "                the src vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            x : Tensor\n",
    "                the encoder outputs\n",
    "            h :\n",
    "                the hidden state\n",
    "            c :\n",
    "                the cell state\n",
    "        \"\"\"\n",
    "        # x = self.embedding(x)\n",
    "        # x, (h, c) = self.lstm_1(x)\n",
    "        # x, (h, c) = self.lstm_2(x, (h, c))\n",
    "        #\n",
    "        # return x, h, c\n",
    "        # Add this line to check the shape of the input tensor\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        # Add this line to check the values of the input tensor\n",
    "        print(\"Input values:\", x)\n",
    "        x = self.embedding(x)\n",
    "        # Add this line to check the shape of the embedded tensor\n",
    "        print(\"Embedded shape:\", x.shape)\n",
    "        # Add this line to check the values of the embedded tensor\n",
    "        print(\"Embedded values:\", x)\n",
    "        x, (h, c) = self.lstm_1(x)\n",
    "        # Add this line to check the shape of the LSTM 1 output\n",
    "        print(\"LSTM 1 output shape:\", x.shape)\n",
    "        # Add this line to check the values of the LSTM 1 output\n",
    "        print(\"LSTM 1 output values:\", x)\n",
    "        x, (h, c) = self.lstm_2(x, (h, c))\n",
    "        # Add this line to check the shape of the LSTM 2 output\n",
    "        print(\"LSTM 2 output shape:\", x.shape)\n",
    "        # Add this line to check the values of the LSTM 2 output\n",
    "        print(\"LSTM 2 output values:\", x)\n",
    "        return x, h, c\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"My decoder with a LSTM layer.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size: int, output_size: int, embedding_dim: int) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, embedding_dim)\n",
    "        self.lstm_1 = nn.LSTM(  # type: ignore\n",
    "            embedding_dim, hidden_size, num_layers=2, dropout=0.3, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, self.output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: Tensor, h: Tuple[Tensor, Tensor]) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Forward method for the tensor network.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "            LSTMs, or Long Short-Term Memory units, are a type of recurrent neural\n",
    "            network (RNN) that have feedback connections. This means they can process\n",
    "            sequences of data, retaining a 'memory' of the previous states of the data\n",
    "            as they process each new timestep. This makes them ideal for tasks\n",
    "            involving sequential data, like time series prediction, natural language\n",
    "            processing, and more.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            x : Tensor\n",
    "                the src vector\n",
    "            h : Tuple[Tensor, Tensor]\n",
    "                The hidden statek cell state\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            x :\n",
    "                The prediction\n",
    "            h :\n",
    "                the hidden state\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        x, h = self.lstm_1(x, h)\n",
    "\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x, h\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"The main NN architecture.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_input_size: int,\n",
    "        encoder_hidden_size: int,\n",
    "        decoder_hidden_size: int,\n",
    "        decoder_output_size: int,\n",
    "    ) -> None:\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.hidden_dim = 10\n",
    "        self.encoder = Encoder(encoder_input_size, encoder_hidden_size, self.hidden_dim)\n",
    "        self.decoder = Decoder(decoder_hidden_size, decoder_output_size, self.hidden_dim)\n",
    "\n",
    "    def forward(\n",
    "        self, src: Tensor, trg: Tensor, teacher_forcing_ratio: float = 0.5\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward method for the tensor network.\n",
    "\n",
    "        Todo\n",
    "        ----\n",
    "        * Define the Any's at the return type\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            src : Tensor\n",
    "                the src vector\n",
    "            trg : Tensor\n",
    "                the trg vector\n",
    "            teacher_forcing_ratio : float\n",
    "                the teacher forcing ratio\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            x : Tensor\n",
    "                the prediction\n",
    "            h :\n",
    "                the hidden state\n",
    "            c :\n",
    "                the cell state\n",
    "        \"\"\"\n",
    "        # Initialize an empty tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg.shape[0], trg.shape[1], self.decoder.output_size, device=trg.device)\n",
    "\n",
    "        # First, the source sequence (src) is passed through the encoder\n",
    "        _, hidden, cell = self.encoder(src)\n",
    "\n",
    "        # The initial decoder input is the <sos> token, i.e., the first token of the target sequence\n",
    "        decoder_input = trg[:, 0].unsqueeze(1)\n",
    "\n",
    "        # Iteratively decode each time step\n",
    "        for t in range(1, trg.shape[1]):\n",
    "            # Pass the decoder input, hidden, and cell states to the decoder\n",
    "            decoder_output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "\n",
    "            # Store the decoder output in the outputs tensor\n",
    "            outputs[:, t] = decoder_output.squeeze(1)\n",
    "\n",
    "            # Decide if we will use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # Get the most probable token\n",
    "            top1 = decoder_output.argmax(2)\n",
    "\n",
    "            # If teacher forcing, use the actual next token as next input. If not, use the predicted token\n",
    "            decoder_input = trg[:, t].unsqueeze(1) if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size: int) -> Tuple[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor]]:\n",
    "        \"\"\"Initializes hidden state\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # Initialize hidden states for Encoder\n",
    "        # Encoder has 2 LSTMs with 4 layers each\n",
    "        encoder_h = weight.new(8, batch_size, self.encoder.hidden_size * 4).zero_()\n",
    "        encoder_c = weight.new(8, batch_size, self.encoder.hidden_size * 4).zero_()\n",
    "\n",
    "        # Initialize hidden states for Decoder\n",
    "        # Decoder has 1 LSTM with 2 layers\n",
    "        decoder_h = weight.new(2, batch_size, self.decoder.hidden_size).zero_()\n",
    "        decoder_c = weight.new(2, batch_size, self.decoder.hidden_size).zero_()\n",
    "\n",
    "        if train_on_gpu:\n",
    "            encoder_h, encoder_c = encoder_h.cuda(), encoder_c.cuda()\n",
    "            decoder_h, decoder_c = decoder_h.cuda(), decoder_c.cuda()\n",
    "\n",
    "        return ((encoder_h, encoder_c), (decoder_h, decoder_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"My Vocabulary class.\"\"\"\n",
    "\n",
    "from typing import List\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"A vocabulary.\"\"\"\n",
    "\n",
    "    def __init__(self, debug=False) -> None:\n",
    "        \"\"\"\n",
    "        Vocabulary.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        word2index : dict\n",
    "            A dictionary mapping words to indices.\n",
    "        index2word : dict\n",
    "            A dictionary mapping indices to words.\n",
    "        n_words : int\n",
    "            The number of words in the vocabulary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        debug : bool\n",
    "            If true, will print useful debug information.\n",
    "        \"\"\"\n",
    "        self.word2index = {\n",
    "            \"<PAD>\": 0,\n",
    "            \"<SOS>\": 1,\n",
    "            \"<EOS>\": 2,\n",
    "            \"<UNK>\": 3\n",
    "        }\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.n_words = 4  # Starting count considering the special tokens\n",
    "        self.debug = debug\n",
    "\n",
    "    def add_sentence(self, sentence: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Add a sentence to the vocabulary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : list\n",
    "            A list of words.\n",
    "        \"\"\"\n",
    "        for word in sentence:\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a word to the vocabulary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            A word.\n",
    "        \"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            if self.debug:\n",
    "                print(f\"Added word: {word} with index: {self.n_words}\")\n",
    "\n",
    "    def to_index(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        Convert a word to its index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            A word.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The index of the word or index of \"<UNK>\" for unknown words.\n",
    "        \"\"\"\n",
    "        return self.word2index.get(word, self.word2index[\"<UNK>\"])\n",
    "\n",
    "    def to_word(self, index: int) -> str:\n",
    "        \"\"\"\n",
    "        Convert an index to its word.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            An index.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The word or \"<UNK>\" for unknown indices.\n",
    "        \"\"\"\n",
    "        return self.index2word.get(index, \"<UNK>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a9d2111ec7901b64.arrow\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-87580d26d91c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-87580d26d91c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-87580d26d91c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                         self.batch_first, bool(self.bidirectional))  # type: ignore\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "My main Chat-Bot file, potentially to be converted to the main CLI file.\n",
    "\"\"\"\n",
    "\n",
    "# from .vocabulary import Vocabulary\n",
    "# from .model import Seq2Seq\n",
    "from typing import List, Dict, Any, cast\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from datasets import load_dataset, disable_progress_bar\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Disable all progress bars to avoid the Udacity lack up Jupyter Updates\n",
    "import tqdm\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "class ChatBot:\n",
    "    \"\"\"\n",
    "    A ChatBot utilizing a Sequence to Sequence model.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    debug : bool\n",
    "        Whether to print debugging information.\n",
    "    vocabulary : Vocabulary\n",
    "        The vocabulary object.\n",
    "    model : Seq2Seq\n",
    "        The sequence-to-sequence model.\n",
    "    dataset : Dataset\n",
    "        The dataset to be used.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize the ChatBot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        debug : bool, optional\n",
    "            Whether to print debugging information. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        self.vocabulary = Vocabulary(debug=self.debug)\n",
    "        self.model = None\n",
    "        self.dataset = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_batches(arr, batch_size: int, seq_length: int):\n",
    "        \"\"\"Create a generator that returns batches of size\n",
    "        batch_size x seq_length from arr.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "            arr : dict\n",
    "                Dictionary containing data you want to make batches from.\n",
    "            batch_size :  integer\n",
    "                Batch size, the number of sequences per batch.\n",
    "            seq_length : integer\n",
    "                Number of encoded chars in a sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(arr, torch.Tensor):\n",
    "            arr = torch.tensor(arr)  # Convert to PyTorch tensor\n",
    "\n",
    "        # Determine the number of batches we can make\n",
    "        total = batch_size * seq_length\n",
    "        n_batches = len(arr) // total\n",
    "\n",
    "        # Keep only enough characters to make full batches\n",
    "        arr = arr[: n_batches * total]\n",
    "\n",
    "        # Reshape into batch_size rows\n",
    "        arr = arr.reshape((batch_size, -1))\n",
    "\n",
    "        # Iterate over the batches using a window of size seq_length\n",
    "        for n in range(0, arr.shape[1], seq_length):\n",
    "            x = arr[:, n : n + seq_length]\n",
    "            y = torch.zeros_like(x)\n",
    "            print(f\"x slice shape: {x.shape}\")\n",
    "            print(f\"y slice shape: {y.shape}\")\n",
    "\n",
    "            try:\n",
    "                y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n + seq_length]\n",
    "            except IndexError:\n",
    "                y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "            yield x, y\n",
    "\n",
    "    def load_hyperparameters(self):\n",
    "        \"\"\"\n",
    "        Load the hyperparameters for the model.\n",
    "        \"\"\"\n",
    "        # Set your hyperparameters here. For instance:\n",
    "        self.embedding_dim = 256\n",
    "        self.hidden_size = 512\n",
    "        self.encoder_input_size = len(self.vocabulary.word2index)\n",
    "        self.decoder_output_size = len(self.vocabulary.word2index)\n",
    "        self.learning_rate = 0.001\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 128\n",
    "        self.clip = 5.0\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"\n",
    "        Initialize the Seq2Seq model with the given hyperparameters.\n",
    "        \"\"\"\n",
    "        self.model = Seq2Seq(\n",
    "            encoder_input_size=self.encoder_input_size,\n",
    "            encoder_hidden_size=self.hidden_size,\n",
    "            decoder_hidden_size=self.hidden_size,\n",
    "            decoder_output_size=self.decoder_output_size,\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.learning_rate\n",
    "        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model on the dataset.\n",
    "        \"\"\"\n",
    "        # Define your training loop here\n",
    "        if not self.dataset:\n",
    "            raise ValueError(\"Dataset has not been loaded.\")\n",
    "\n",
    "        if train_on_gpu:\n",
    "            self.model.cuda()\n",
    "\n",
    "        counter = 0\n",
    "        n_chars = len(self.vocabulary.word2index)\n",
    "        if self.debug:\n",
    "            print(\"Vocabulary Size (n_chars):\", n_chars)\n",
    "        for epoch in range(self.epochs):\n",
    "            if self.debug:\n",
    "                print(f\"Training epoch: {epoch+1}/{self.epochs}\")\n",
    "\n",
    "            # Initialize hidden state\n",
    "            h = self.model.init_hidden(batch_size=self.batch_size)\n",
    "\n",
    "            # for x, y in self.get_batches(\n",
    "            #     self.train_data, batch_size=self.batch_size, seq_length=n_chars\n",
    "            # ):\n",
    "            # for (attention_mask, input_ids, label, token_type_ids) in self.dataloader:\n",
    "            for (_, x, y, __) in self.dataloader:\n",
    "                counter += 1\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"Shapes: x, y: {(x.shape, y.shape)}\", end=\"\")\n",
    "\n",
    "                x = torch.nn.functional.one_hot(x, num_classes=n_chars)\n",
    "                if self.debug:\n",
    "                    print(f\"One-hot encoded x shape: {x.shape}\")\n",
    "\n",
    "                x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                if train_on_gpu:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"x shape: {x.shape}, y shape: {y.shape}\")\n",
    "\n",
    "                self.model.zero_grad()\n",
    "                if self.debug:\n",
    "                    print(\"Zero Graded....\", end=\"\")\n",
    "\n",
    "                output, h = self.model(x, h)\n",
    "                if self.debug:\n",
    "                    print(f\"output shape: {output.shape}\", end=\"\")\n",
    "\n",
    "                loss = self.criterion(output, y)\n",
    "                if self.debug:\n",
    "                    print(\"\\rGot Loss....\", end=\"\")\n",
    "\n",
    "                loss.backward()\n",
    "                if self.debug:\n",
    "                    print(\"\\rGot Backward....\", end=\"\")\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
    "                self.optimizer.step()\n",
    "                if self.debug:\n",
    "                    print(\"\\rGot Optimized....\", end=\"\")\n",
    "\n",
    "                if counter % 100 == 0:\n",
    "                    if self.debug:\n",
    "                        print(\"\\r\", end=\"\")\n",
    "                    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def suppress_output(self):\n",
    "        \"\"\"\n",
    "        Udacity has NOT update it's jupyter notebook, use this to suppress\n",
    "\n",
    "        ImportError: FloatProgress not found. Please update jupyter and ipywidgets.\n",
    "        See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "        \"\"\"\n",
    "        with open(os.devnull, 'w') as fnull:\n",
    "            old_out = os.dup(1)\n",
    "            old_err = os.dup(2)\n",
    "            os.dup2(fnull.fileno(), 1)\n",
    "            os.dup2(fnull.fileno(), 2)\n",
    "            try:\n",
    "                yield\n",
    "            finally:\n",
    "                os.dup2(old_out, 1)\n",
    "                os.dup2(old_err, 2)\n",
    "                os.close(old_out)\n",
    "                os.close(old_err)\n",
    "\n",
    "    def load_dataset(self, dataset_name=\"glue\"):\n",
    "        \"\"\"\n",
    "        Load a dataset using huggingface datasets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset_name : str, optional\n",
    "            The name of the dataset. Defaults to \"glue\".\n",
    "        \"\"\"\n",
    "\n",
    "        with self.suppress_output():\n",
    "            self.dataset = load_dataset(dataset_name, \"mrpc\", split=\"train\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "            self.dataset = self.dataset.map(\n",
    "                lambda e: tokenizer(e[\"sentence1\"], truncation=True, padding=\"max_length\"),\n",
    "                batched=True,\n",
    "            )\n",
    "\n",
    "            if train_on_gpu:\n",
    "                self.dataset.set_format(\n",
    "                    type=\"torch\",\n",
    "                    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"],\n",
    "                    device=\"cuda\",\n",
    "                )\n",
    "            else:\n",
    "                self.dataset.set_format(\n",
    "                    type=\"torch\",\n",
    "                    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"],\n",
    "                )\n",
    "            # self.dataloader = DataLoader(self.dataset, batch_size=self.batch_size)\n",
    "            self.dataloader = DataLoader(self.dataset)\n",
    "\n",
    "    def assert_seq2seq(self):\n",
    "        \"\"\"\n",
    "        Assert the Seq2Seq model to ensure its correctness.\n",
    "        \"\"\"\n",
    "        # Add your assertion code here\n",
    "        pass\n",
    "\n",
    "    def use_pretrained_embeddings(self, embeddings):\n",
    "        \"\"\"\n",
    "        Optionally use pretrained word embeddings in the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddings : Any\n",
    "            The pre-trained embeddings.\n",
    "        \"\"\"\n",
    "        # If you decide to use pre-trained embeddings, implement this method.\n",
    "        pass\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model's performance.\n",
    "        \"\"\"\n",
    "        # You can implement methods to evaluate your model's performance here.\n",
    "        pass\n",
    "\n",
    "    def interact(self):\n",
    "        \"\"\"\n",
    "        Interact with the chatbot.\n",
    "        \"\"\"\n",
    "        # Here you'll write code to interact with the model in a dialogue manner.\n",
    "        pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the chatbot.\n",
    "    \"\"\"\n",
    "    bot = ChatBot(debug=True)\n",
    "\n",
    "\n",
    "    disable_progress_bar()\n",
    "    tqdm.tqdm.disable = True\n",
    "    bot.load_dataset()\n",
    "    bot.load_hyperparameters()\n",
    "    bot.initialize_model()\n",
    "\n",
    "    bot.train()\n",
    "\n",
    "    bot.interact()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
